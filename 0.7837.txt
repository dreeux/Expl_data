require("h2o") ;require("h2oEnsemble"); require("SuperLearner"); require("cvAUC")

library(readr); library(xgboost); library(doParallel); library(caret); library(Metrics)

set.seed(8675309) 

train <- read_csv("D:/kaggle/Springleaf/DATA/CSV/train.csv")

  # save ID and response
  
  train_target <- train$target
  
  train$target <- NULL
  
  train_ID <- train$ID
  
  train$ID <- NULL
  
  train$VAR_0241 <- as.numeric(as.character(train$VAR_0241))
  
  
  test <- read_csv("D:/kaggle/Springleaf/DATA/CSV/test.csv")
  
  # save ID and response
  
  test_ID <- test$ID
  
  test$ID <- NULL
  
  test$VAR_0241 <- as.numeric(as.character(test$VAR_0241))
  
  print(dim(train)); print(dim(test))
  
  #To find date columns -- really didn`t understand how
  
  datecolumns = c("VAR_0073", "VAR_0075", "VAR_0156", "VAR_0157", "VAR_0158", 
                  "VAR_0159", "VAR_0166", "VAR_0167", "VAR_0168", "VAR_0176", 
                  "VAR_0177", "VAR_0178", "VAR_0179", "VAR_0204", "VAR_0217")
  
  train_cropped <- train[datecolumns]
  
  train_cc <- data.frame(apply(train_cropped, 2, function(x) as.double(strptime(x, 
                                                              
                        format='%d%b%y:%H:%M:%S', tz="UTC"))))
  
  #check how resonse varies with change in representation of date (month, year etc also check which day/month/year
  
  # has highest loan buyers i.e. check for seasonality trends)
  
  for (dc in datecolumns){
    
    train[dc] <- NULL
    
    train[dc] <- train_cc[dc]
  }
  
  train_cc <- NULL
  
  train_cropped <- NULL
  
  gc()
  
  test_cropped <- test[datecolumns]
  
  test_cc <- data.frame(apply(test_cropped, 2, function(x) as.double(strptime(x, 
  
                        format='%d%b%y:%H:%M:%S', tz="UTC"))))
  
  for (dc in datecolumns){
    
    test[dc] <- NULL
    
    test[dc] <- test_cc[dc]
  
    }
  
  test_cc <- NULL
  
  test_cropped <- NULL
  
  gc()
  
  feature.names <- names(train)[1:ncol(train)]
  
  for (f in feature.names) {
    
    if (class(train[[f]])=="character") {
      
      levels <- unique(c(train[[f]], test[[f]]))
      
      train[[f]] <- as.integer(factor(train[[f]], levels=levels))
      
      test[[f]]  <- as.integer(factor(test[[f]],  levels=levels))
    }
    
  }
  
  print(dim(train)); print(dim(test))
  #dates seem to be skewed towards right , applying Box Cox transforms to both train and test
  
  
  train_pre <-  preProcess(train[datecolumns], method = ("BoxCox"))
                                                         
                                                         
  train_pre_pred <- predict(train_pre, train[datecolumns])
                                                         
  train[datecolumns] <- train_pre_pred
                                                         
                                                         
  test_pre <-  preProcess(test[datecolumns], method = ("BoxCox")) 
                                                                                                              
  test_pre_pred <- predict(test_pre, test[datecolumns])
                                                                                                              
  test[datecolumns] <- test_pre_pred
                                                                                                              
  print(dim(train)); print(dim(test))
                                                                                                              
########################################################################################
                                                                                                            
#This data set has large number of nzv removing them
                                                                                                            
nzv <- nearZeroVar(train)
                                                                                                            
nzv_test <- nearZeroVar(test)
                                                                                                            
train <- train[, -nzv]

test <- test[, -nzv_test]
                                                                                                            
print(dim(train)); print(dim(test))
                                                                                                            

#train_pre_total <-  preProcess(train[ , !(names(train) %in% datecolumns)], method =   "scale") 

#train_pre_pred <- predict(train_pre_total, train[ , !(names(train) %in% datecolumns)])

#train[ , !(names(train) %in% datecolumns)] <- train_pre_pred


#test_pre_total <-  preProcess(test[, !(names(test) %in% datecolumns)], method = "scale")

#test_pre_pred <- predict(test_pre_total, test[ , !(names(test) %in% datecolumns)])

#test[ , !(names(test) %in% datecolumns)] <- test_pre_pred

#print(dim(train)); print(dim(test))


train[is.na(train)] <- 0

test[is.na(test)]   <- 0

rm( "cl", "clf", "datecolumns", "dc", "dtrain", "dval", "eigth", "f", "feature.names", "fifth",          
     "first", "fourth", "levels", "ninth", "nn", "nn_predict", "nzv", "nzv_test", "param", "second",         
     "seventh", "sixth", "split", "sub", "submission" )

rm(list, tenth, test_cc, test_cropped, test_pre, test_pre_pred, test_pre_total, third, 
   
   train_cc, train_pre, train_pre_pred, train_pre_total, watchlist, x, X, y, y_train, 
   
   y_val, train_cropped)

#########################################################################################
gc()

localH2O <- h2o.init(max_mem_size = "10g")

train_target <- as.factor(train_target)

train$ID <- train_ID; train$target <- train_target

test$ID <- test_ID

feature.names <- names(train[1:(ncol(train) -2) ])

train.hex <- as.h2o(localH2O, object = train)

test.hex <- as.h2o(localH2O, object = test)

split <- h2o.runif(train.hex, 1234)

training.hex <- h2o.assign(train.hex[split<0.8,], "training.hex")

validation.hex <- h2o.assign(train.hex[split>=0.8,], "validation.hex")


learner <- c("h2o.randomForest.3",
             
             "h2o.randomForest.2",
             
             "h2o.randomForest.1"
             
)
metalearner <- "SL.glm"

family <- "binomial"

h2o.randomForest.3 <- function(..., ntrees = 500, nbins = 100, seed = 3565) {
  
  h2o.randomForest.wrapper(..., ntrees = ntrees, nbins = nbins, seed = seed)
  
}

h2o.randomForest.2 <- function(..., ntrees = 800, nbins = 25, seed = 9999) {
  
  h2o.randomForest.wrapper(..., ntrees = ntrees, nbins = nbins, seed = seed)
  
}

h2o.randomForest.1 <- function(..., ntrees = 900, nbins = 75, seed = 1) {
  
  h2o.randomForest.wrapper(..., ntrees = ntrees, nbins = nbins, seed = seed)

}

fit <- h2o.ensemble(x = feature.names, y = "target",
                    
                    training_frame = training.hex, 
                    
                    validation_frame = validation.hex,
                    
                    family = family, 
                    
                    learner = learner, 
                    
                    metalearner = metalearner,
                    
                    cvControl = list(V = 5, shuffle = TRUE))
